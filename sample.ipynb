{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Manteswami Kavya\n",
      "Saved article: Berthelsdorf Formation\n",
      "Saved article: Paraglaciecola arctica\n",
      "Saved article: Glory Glory (football chant)\n",
      "Saved article: Le Gheer\n",
      "Saved article: Edmond N'Tiamoah\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:02<04:43,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Horatio Stockton Howell\n",
      "Saved article: 2019 World Junior Wrestling Championships\n",
      "Saved article: Consumer Electronics Control\n",
      "Saved article: Coal Gap School\n",
      "Saved article: Una Croce senza nome\n",
      "Saved article: Live and Electric at the Union Chapel\n",
      "Saved article: White-rumped tanager\n",
      "Saved article: Gila Wilderness\n",
      "Saved article: Hassan Farid Didi\n",
      "Saved article: Villa Wartholz\n",
      "Saved article: Matthew Murphy\n",
      "Saved article: Michigan goal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kobori/anaconda3/envs/wiki/lib/python3.10/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /home/kobori/anaconda3/envs/wiki/lib/python3.10/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped disambiguation page: ['Democratic Renewal Party (Angola)', 'Democratic Renovator Party (Portugal)', 'Renovation (disambiguation)', 'Democratic Party (disambiguation)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:03<00:29,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Alileh Sar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:04<00:13,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Burnham Norton\n",
      "Saved article: Arnaud-François Lefèbvre\n",
      "Saved article: FIL European Luge Championships 2018\n",
      "Saved article: Boom (navigational barrier)\n",
      "Saved article: Napan, New Brunswick\n",
      "Saved article: Sovetskaya Street\n",
      "Saved article: Verougstraete\n",
      "Saved article: Roman Catholic Diocese of Laval\n",
      "Saved article: Territorial Abbey of Montevergine\n",
      "Saved article: Ricardo Cabrera Martínez\n",
      "Saved article: Bobr (urban-type settlement)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:05<00:11,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Blythe River (Tasmania)\n",
      "Skipped disambiguation page: ['Walter I of Brienne', 'Walter II of Brienne', 'Walter III of Brienne', 'Walter IV of Brienne', 'Walter V of Brienne', 'Walter VI of Brienne', 'Walter IV of Enghien', 'County of Brienne']\n",
      "Saved article: SMK Kok Lanas\n",
      "Saved article: Luc Argand\n",
      "Skipped disambiguation page: ['Buchanan County, Iowa', 'Buchanan County, Missouri', 'Buchanan County, Virginia']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [00:05<00:10,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Pingyangmiao, You County\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [00:05<00:04, 13.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: The Manchester Man (novel)\n",
      "Saved article: Baker Bridge train wreck\n",
      "Saved article: Mangelia barbadoides\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [00:07<00:06,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Guy Wyndham\n",
      "Saved article: McCamley\n",
      "Saved article: You're Beautiful (Nathaniel Willemse song)\n",
      "Saved article: Olga James\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:07<00:05,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Parkenfestivalen\n",
      "Saved article: Deterministic memory\n",
      "Saved article: Carson City and Indian Village\n",
      "Saved article: Milia-like calcinosis\n",
      "Saved article: Loxocrambus mohaviellus\n",
      "Saved article: Chenar Bagali\n",
      "Saved article: Arnaud Desjardins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [00:07<00:03, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: David Yencken\n",
      "Saved article: Gianclaudio Bressa\n",
      "Saved article: Jim Pena\n",
      "Saved article: Book Art\n",
      "Saved article: Airbus UK Broughton F.C.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [00:08<00:03, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped disambiguation page: ['Boot Hill (video game)', 'Boot Hill (film)', 'Boot Hill (role-playing game)', 'Boot Hill Bowl', 'Johnny Winter', 'Boot Hill', 'Boot Hill Museum', 'Glossary of cricket terms#B']\n",
      "Saved article: Casalvecchio Siculo\n",
      "Saved article: Rod Anderson (writer)\n",
      "Saved article: Hendren Building\n",
      "Saved article: Germany–Tanzania relations\n",
      "Saved article: Tindal Bluff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [00:09<00:07,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Fengxin Road station\n",
      "Saved article: European honey buzzard\n",
      "Saved article: Dorothy Brandon\n",
      "Saved article: 1049 Gotho\n",
      "Saved article: London 1980 International Stamp Exhibition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [00:09<00:06,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Rock Creek Park Golf Course\n",
      "Saved article: Safsaf massacre\n",
      "Saved article: Grotella septempunctata\n",
      "Saved article: Fear of the Digital Remix\n",
      "Saved article: Nothing but Hope and Passion\n",
      "Saved article: Alfred Worden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [00:09<00:01, 13.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Oral pontine reticular nucleus\n",
      "Saved article: Barar Deh, Dodangeh\n",
      "Saved article: Uki waza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [00:10<00:01, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: 2016 KNSB Dutch Single Distance Championships – Women's 3000 m\n",
      "Saved article: 1963 Nova Scotia general election\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [00:11<00:02,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: USS Sagittarius\n",
      "Saved article: Matam Region\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [00:11<00:00, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Motor unit\n",
      "Saved article: Saint Michel d'Aiguilhe\n",
      "Saved article: 1995 CFL season\n",
      "Saved article: Rok Urbanc\n",
      "Saved article: Beach Park Isles\n",
      "Saved article: Mafalda of Castile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [00:11<00:00, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Herbert McCabe\n",
      "Saved article: Ahrue Luster\n",
      "Saved article: Peter Sainthill (died 1571)\n",
      "Skipped disambiguation page: ['David Zilberman (wrestler)', 'David B. Zilberman', 'David Zilberman (economist)']\n",
      "Saved article: Assistant Secretary of Defense for Health Affairs\n",
      "Saved article: William Rant\n",
      "Saved article: Somerset v Stewart\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Joel Hitt\n",
      "Saved article: San Francisco Writers Grotto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import wikipedia\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "# output_wikiディレクトリを作成\n",
    "os.makedirs(\"output_wiki\", exist_ok=True)\n",
    "\n",
    "# 全ての英語Wikipediaページのタイトルを取得する\n",
    "all_titles = list(wikipedia.random(pages=5000))  # 5000ページ分のタイトルを取得\n",
    "\n",
    "# 100個のタイトルをランダムに選択する\n",
    "selected_titles = random.sample(all_titles, 100)\n",
    "\n",
    "def download_page(args):\n",
    "    i, title = args\n",
    "    try:\n",
    "        page = wikipedia.page(title)\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        # 記事が見つからない場合はスキップ\n",
    "        return\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        # 曖昧な記事はスキップする\n",
    "        print(f\"Skipped disambiguation page: {e.options}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    else:\n",
    "        filename = os.path.join(\"output_wiki\", f\"{i:03d}.txt\")\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(page.content)\n",
    "        print(f\"Saved article: {page.title}\")\n",
    "\n",
    "# 選択したタイトルの記事を取得し、保存する\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    list(tqdm(executor.map(download_page, enumerate(selected_titles, start=1)), total=len(selected_titles)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文の分割が完了しました。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kobori/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# NLTKのデータをダウンロード\n",
    "nltk.download('punkt')\n",
    "\n",
    "# output_wikiディレクトリのパス\n",
    "wiki_dir = \"output_wiki\"\n",
    "\n",
    "# output_textディレクトリを作成\n",
    "output_dir = \"output_text\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# output_wikiディレクトリ内のファイルを処理\n",
    "for filename in os.listdir(wiki_dir):\n",
    "    # ファイルパスを構築\n",
    "    file_path = os.path.join(wiki_dir, filename)\n",
    "\n",
    "    # ファイルを読み込む\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # 記事を1文ずつに分割\n",
    "    sentences = sent_tokenize(content)\n",
    "\n",
    "    # output_textディレクトリ内にサブディレクトリを作成\n",
    "    sub_dir_name = os.path.splitext(filename)[0]\n",
    "    sub_dir_path = os.path.join(output_dir, sub_dir_name)\n",
    "    os.makedirs(sub_dir_path, exist_ok=True)\n",
    "\n",
    "    # 分割した文をファイルに保存\n",
    "    for i, sentence in enumerate(sentences, start=1):\n",
    "        sentence_filename = os.path.join(sub_dir_path, f\"{i:03d}.txt\")\n",
    "        with open(sentence_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(sentence)\n",
    "\n",
    "print(\"文の分割が完了しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Processing subdirectory 1/90: 100%|██████████| 5/5 [00:06<00:00,  1.25s/file]\n",
      "Processing subdirectory 2/90: 100%|██████████| 83/83 [01:22<00:00,  1.00file/s]\n",
      "Processing subdirectory 3/90: 100%|██████████| 3/3 [00:02<00:00,  1.33file/s]\n",
      "Processing subdirectory 4/90: 100%|██████████| 6/6 [00:04<00:00,  1.31file/s]\n",
      "Processing subdirectory 5/90: 100%|██████████| 51/51 [00:44<00:00,  1.14file/s]\n",
      "Processing subdirectory 6/90: 100%|██████████| 10/10 [00:07<00:00,  1.27file/s]\n",
      "Processing subdirectory 7/90: 100%|██████████| 14/14 [00:10<00:00,  1.31file/s]\n",
      "Processing subdirectory 8/90: 100%|██████████| 13/13 [00:14<00:00,  1.09s/file]\n",
      "Processing subdirectory 9/90: 100%|██████████| 10/10 [00:13<00:00,  1.37s/file]\n",
      "Processing subdirectory 10/90: 100%|██████████| 3/3 [00:05<00:00,  1.74s/file]\n",
      "Processing subdirectory 11/90: 100%|██████████| 14/14 [00:16<00:00,  1.16s/file]\n",
      "Processing subdirectory 12/90: 100%|██████████| 43/43 [00:35<00:00,  1.23file/s]\n",
      "Processing subdirectory 13/90: 100%|██████████| 53/53 [00:44<00:00,  1.18file/s]\n",
      "Processing subdirectory 14/90: 100%|██████████| 36/36 [00:34<00:00,  1.03file/s]\n",
      "Processing subdirectory 15/90: 100%|██████████| 4/4 [00:03<00:00,  1.26file/s]\n",
      "Processing subdirectory 16/90: 100%|██████████| 22/22 [00:23<00:00,  1.05s/file]\n",
      "Processing subdirectory 17/90: 100%|██████████| 5/5 [00:03<00:00,  1.32file/s]\n",
      "Processing subdirectory 18/90: 100%|██████████| 2/2 [00:06<00:00,  3.08s/file]\n",
      "Processing subdirectory 19/90: 100%|██████████| 7/7 [00:11<00:00,  1.61s/file]\n",
      "Processing subdirectory 20/90: 100%|██████████| 15/15 [00:23<00:00,  1.59s/file]\n",
      "Processing subdirectory 21/90: 100%|██████████| 4/4 [00:03<00:00,  1.28file/s]\n",
      "Processing subdirectory 22/90: 100%|██████████| 59/59 [00:49<00:00,  1.19file/s]\n",
      "Processing subdirectory 23/90: 100%|██████████| 2/2 [00:01<00:00,  1.13file/s]\n",
      "Processing subdirectory 24/90: 100%|██████████| 56/56 [00:54<00:00,  1.03file/s]\n",
      "Processing subdirectory 25/90: 100%|██████████| 3/3 [00:02<00:00,  1.01file/s]\n",
      "Processing subdirectory 26/90: 100%|██████████| 3/3 [00:03<00:00,  1.21s/file]\n",
      "Processing subdirectory 27/90: 100%|██████████| 13/13 [00:19<00:00,  1.48s/file]\n",
      "Processing subdirectory 28/90: 100%|██████████| 5/5 [00:06<00:00,  1.39s/file]\n",
      "Processing subdirectory 29/90: 100%|██████████| 9/9 [00:08<00:00,  1.06file/s]\n",
      "Processing subdirectory 30/90: 100%|██████████| 20/20 [00:18<00:00,  1.09file/s]\n",
      "Processing subdirectory 31/90: 100%|██████████| 21/21 [00:23<00:00,  1.12s/file]\n",
      "Processing subdirectory 32/90: 100%|██████████| 3/3 [00:02<00:00,  1.19file/s]\n",
      "Processing subdirectory 33/90: 100%|██████████| 42/42 [00:35<00:00,  1.17file/s]\n",
      "Processing subdirectory 34/90: 100%|██████████| 19/19 [00:21<00:00,  1.12s/file]\n",
      "Processing subdirectory 35/90: 100%|██████████| 2/2 [00:04<00:00,  2.23s/file]\n",
      "Processing subdirectory 36/90: 100%|██████████| 15/15 [00:22<00:00,  1.47s/file]\n",
      "Processing subdirectory 37/90: 100%|██████████| 3/3 [00:02<00:00,  1.02file/s]\n",
      "Processing subdirectory 38/90: 100%|██████████| 21/21 [00:18<00:00,  1.15file/s]\n",
      "Processing subdirectory 39/90: 100%|██████████| 2/2 [00:04<00:00,  2.11s/file]\n",
      "Processing subdirectory 40/90: 100%|██████████| 3/3 [00:05<00:00,  1.68s/file]\n",
      "Processing subdirectory 41/90: 100%|██████████| 4/4 [00:02<00:00,  1.66file/s]\n",
      "Processing subdirectory 42/90: 100%|██████████| 5/5 [00:06<00:00,  1.33s/file]\n",
      "Processing subdirectory 43/90: 100%|██████████| 178/178 [02:55<00:00,  1.01file/s]\n",
      "Processing subdirectory 44/90: 100%|██████████| 8/8 [00:09<00:00,  1.13s/file]\n",
      "Processing subdirectory 45/90: 100%|██████████| 13/13 [00:13<00:00,  1.03s/file]\n",
      "Processing subdirectory 46/90: 100%|██████████| 7/7 [00:10<00:00,  1.52s/file]\n",
      "Processing subdirectory 47/90: 100%|██████████| 27/27 [00:31<00:00,  1.16s/file]\n",
      "Processing subdirectory 48/90: 100%|██████████| 134/134 [01:48<00:00,  1.23file/s]\n",
      "Processing subdirectory 49/90: 100%|██████████| 12/12 [00:12<00:00,  1.04s/file]\n",
      "Processing subdirectory 50/90: 100%|██████████| 29/29 [00:27<00:00,  1.05file/s]\n",
      "Processing subdirectory 51/90: 100%|██████████| 20/20 [00:21<00:00,  1.08s/file]\n",
      "Processing subdirectory 52/90: 100%|██████████| 3/3 [00:04<00:00,  1.54s/file]\n",
      "Processing subdirectory 53/90: 100%|██████████| 6/6 [00:03<00:00,  1.56file/s]\n",
      "Processing subdirectory 54/90: 100%|██████████| 8/8 [00:05<00:00,  1.40file/s]\n",
      "Processing subdirectory 55/90: 100%|██████████| 14/14 [00:14<00:00,  1.06s/file]\n",
      "Processing subdirectory 56/90: 100%|██████████| 16/16 [00:15<00:00,  1.02file/s]\n",
      "Processing subdirectory 57/90: 100%|██████████| 6/6 [00:06<00:00,  1.17s/file]\n",
      "Processing subdirectory 58/90: 100%|██████████| 5/5 [00:05<00:00,  1.16s/file]\n",
      "Processing subdirectory 59/90: 100%|██████████| 7/7 [00:07<00:00,  1.08s/file]\n",
      "Processing subdirectory 60/90: 100%|██████████| 37/37 [00:38<00:00,  1.05s/file]\n",
      "Processing subdirectory 61/90: 100%|██████████| 239/239 [03:47<00:00,  1.05file/s]\n",
      "Processing subdirectory 62/90: 100%|██████████| 3/3 [00:05<00:00,  1.68s/file]\n",
      "Processing subdirectory 63/90: 100%|██████████| 40/40 [00:55<00:00,  1.38s/file]\n",
      "Processing subdirectory 64/90: 100%|██████████| 6/6 [00:04<00:00,  1.25file/s]\n",
      "Processing subdirectory 65/90: 100%|██████████| 2/2 [00:01<00:00,  1.09file/s]\n",
      "Processing subdirectory 66/90: 100%|██████████| 57/57 [00:47<00:00,  1.20file/s]\n",
      "Processing subdirectory 67/90: 100%|██████████| 43/43 [00:49<00:00,  1.15s/file]\n",
      "Processing subdirectory 68/90: 100%|██████████| 17/17 [00:21<00:00,  1.25s/file]\n",
      "Processing subdirectory 69/90: 100%|██████████| 3/3 [00:04<00:00,  1.54s/file]\n",
      "Processing subdirectory 70/90: 100%|██████████| 3/3 [00:01<00:00,  1.50file/s]\n",
      "Processing subdirectory 71/90: 100%|██████████| 24/24 [00:18<00:00,  1.28file/s]\n",
      "Processing subdirectory 72/90: 100%|██████████| 3/3 [00:04<00:00,  1.61s/file]\n",
      "Processing subdirectory 73/90: 100%|██████████| 23/23 [00:18<00:00,  1.22file/s]\n",
      "Processing subdirectory 74/90: 100%|██████████| 18/18 [00:16<00:00,  1.11file/s]\n",
      "Processing subdirectory 75/90: 100%|██████████| 40/40 [00:36<00:00,  1.10file/s]\n",
      "Processing subdirectory 76/90: 100%|██████████| 53/53 [00:37<00:00,  1.40file/s]\n",
      "Processing subdirectory 77/90: 100%|██████████| 12/12 [00:13<00:00,  1.14s/file]\n",
      "Processing subdirectory 78/90: 100%|██████████| 29/29 [00:29<00:00,  1.03s/file]\n",
      "Processing subdirectory 79/90: 100%|██████████| 4/4 [00:02<00:00,  1.57file/s]\n",
      "Processing subdirectory 80/90: 100%|██████████| 17/17 [00:15<00:00,  1.11file/s]\n",
      "Processing subdirectory 81/90: 100%|██████████| 31/31 [00:37<00:00,  1.20s/file]\n",
      "Processing subdirectory 82/90: 100%|██████████| 24/24 [00:18<00:00,  1.27file/s]\n",
      "Processing subdirectory 83/90: 100%|██████████| 19/19 [00:16<00:00,  1.17file/s]\n",
      "Processing subdirectory 84/90: 100%|██████████| 28/28 [00:38<00:00,  1.37s/file]\n",
      "Processing subdirectory 85/90: 100%|██████████| 4/4 [00:06<00:00,  1.71s/file]\n",
      "Processing subdirectory 86/90: 100%|██████████| 2/2 [00:02<00:00,  1.04s/file]\n",
      "Processing subdirectory 87/90: 100%|██████████| 4/4 [00:05<00:00,  1.31s/file]\n",
      "Processing subdirectory 88/90: 100%|██████████| 20/20 [00:16<00:00,  1.25file/s]\n",
      "Processing subdirectory 89/90: 100%|██████████| 29/29 [00:41<00:00,  1.43s/file]\n",
      "Processing subdirectory 90/90: 100%|██████████| 3/3 [00:04<00:00,  1.57s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "翻訳が完了しました。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pysbd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm  # プログレスバーを表示するためのライブラリ\n",
    "\n",
    "# 翻訳モデルの設定\n",
    "fugu_translator = pipeline('translation', model='staka/fugumt-en-ja')\n",
    "\n",
    "# output_textディレクトリのパス\n",
    "input_dir = \"output_text\"\n",
    "\n",
    "# output_japanese_textディレクトリを作成\n",
    "output_dir = \"output_japanese_text\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# サブディレクトリの総数を取得\n",
    "total_subdirs = len(os.listdir(input_dir))\n",
    "\n",
    "# output_textディレクトリ内のサブディレクトリを処理\n",
    "for i, sub_dir_name in enumerate(os.listdir(input_dir), start=1):\n",
    "    sub_dir_path = os.path.join(input_dir, sub_dir_name)\n",
    "\n",
    "    # output_japanese_textディレクトリ内にサブディレクトリを作成\n",
    "    output_sub_dir_path = os.path.join(output_dir, sub_dir_name)\n",
    "    os.makedirs(output_sub_dir_path, exist_ok=True)\n",
    "\n",
    "    # サブディレクトリ内のファイルを処理\n",
    "    files = os.listdir(sub_dir_path)\n",
    "    for filename in tqdm(files, desc=f\"Processing subdirectory {i}/{total_subdirs}\", unit=\"file\"):\n",
    "        file_path = os.path.join(sub_dir_path, filename)\n",
    "\n",
    "        # ファイルを読み込む\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # 英語の文章を1文ずつに分割\n",
    "        seg_en = pysbd.Segmenter(language=\"en\", clean=False)\n",
    "        sentences_en = seg_en.segment(content)\n",
    "\n",
    "        # 英語から日本語に翻訳\n",
    "        translations = fugu_translator(sentences_en)\n",
    "\n",
    "        # 翻訳された内容をファイルに保存\n",
    "        output_file_path = os.path.join(output_sub_dir_path, filename)\n",
    "        with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for translation in translations:\n",
    "                f.write(translation['translation_text'] + \"\\n\")\n",
    "\n",
    "print(\"翻訳が完了しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 音声ファイルに変換する\n",
    "import os\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
    "\n",
    "os.makedirs(\"audio_files\", exist_ok=True)\n",
    "\n",
    "model_name = \"facebook/wav2vec2-large-xlsr-japanese\"\n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(model_name)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name)\n",
    "\n",
    "for i, ja_sentence in enumerate(ja_sentences):\n",
    "    speech = model.generate(tokenizer(ja_sentence, return_tensors=\"pt\").input_ids)\n",
    "    filename = f\"audio_files/sentence_{i}.wav\"\n",
    "    tokenizer.save_audio(speech, filename)\n",
    "    print(f\"Saved audio file: {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wiki",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
