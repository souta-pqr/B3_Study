{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Manteswami Kavya\n",
      "Saved article: Berthelsdorf Formation\n",
      "Saved article: Paraglaciecola arctica\n",
      "Saved article: Glory Glory (football chant)\n",
      "Saved article: Le Gheer\n",
      "Saved article: Edmond N'Tiamoah\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:02<04:43,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Horatio Stockton Howell\n",
      "Saved article: 2019 World Junior Wrestling Championships\n",
      "Saved article: Consumer Electronics Control\n",
      "Saved article: Coal Gap School\n",
      "Saved article: Una Croce senza nome\n",
      "Saved article: Live and Electric at the Union Chapel\n",
      "Saved article: White-rumped tanager\n",
      "Saved article: Gila Wilderness\n",
      "Saved article: Hassan Farid Didi\n",
      "Saved article: Villa Wartholz\n",
      "Saved article: Matthew Murphy\n",
      "Saved article: Michigan goal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kobori/anaconda3/envs/wiki/lib/python3.10/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /home/kobori/anaconda3/envs/wiki/lib/python3.10/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped disambiguation page: ['Democratic Renewal Party (Angola)', 'Democratic Renovator Party (Portugal)', 'Renovation (disambiguation)', 'Democratic Party (disambiguation)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:03<00:29,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Alileh Sar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:04<00:13,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Burnham Norton\n",
      "Saved article: Arnaud-François Lefèbvre\n",
      "Saved article: FIL European Luge Championships 2018\n",
      "Saved article: Boom (navigational barrier)\n",
      "Saved article: Napan, New Brunswick\n",
      "Saved article: Sovetskaya Street\n",
      "Saved article: Verougstraete\n",
      "Saved article: Roman Catholic Diocese of Laval\n",
      "Saved article: Territorial Abbey of Montevergine\n",
      "Saved article: Ricardo Cabrera Martínez\n",
      "Saved article: Bobr (urban-type settlement)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:05<00:11,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Blythe River (Tasmania)\n",
      "Skipped disambiguation page: ['Walter I of Brienne', 'Walter II of Brienne', 'Walter III of Brienne', 'Walter IV of Brienne', 'Walter V of Brienne', 'Walter VI of Brienne', 'Walter IV of Enghien', 'County of Brienne']\n",
      "Saved article: SMK Kok Lanas\n",
      "Saved article: Luc Argand\n",
      "Skipped disambiguation page: ['Buchanan County, Iowa', 'Buchanan County, Missouri', 'Buchanan County, Virginia']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [00:05<00:10,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Pingyangmiao, You County\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [00:05<00:04, 13.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: The Manchester Man (novel)\n",
      "Saved article: Baker Bridge train wreck\n",
      "Saved article: Mangelia barbadoides\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [00:07<00:06,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Guy Wyndham\n",
      "Saved article: McCamley\n",
      "Saved article: You're Beautiful (Nathaniel Willemse song)\n",
      "Saved article: Olga James\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:07<00:05,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Parkenfestivalen\n",
      "Saved article: Deterministic memory\n",
      "Saved article: Carson City and Indian Village\n",
      "Saved article: Milia-like calcinosis\n",
      "Saved article: Loxocrambus mohaviellus\n",
      "Saved article: Chenar Bagali\n",
      "Saved article: Arnaud Desjardins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [00:07<00:03, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: David Yencken\n",
      "Saved article: Gianclaudio Bressa\n",
      "Saved article: Jim Pena\n",
      "Saved article: Book Art\n",
      "Saved article: Airbus UK Broughton F.C.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [00:08<00:03, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped disambiguation page: ['Boot Hill (video game)', 'Boot Hill (film)', 'Boot Hill (role-playing game)', 'Boot Hill Bowl', 'Johnny Winter', 'Boot Hill', 'Boot Hill Museum', 'Glossary of cricket terms#B']\n",
      "Saved article: Casalvecchio Siculo\n",
      "Saved article: Rod Anderson (writer)\n",
      "Saved article: Hendren Building\n",
      "Saved article: Germany–Tanzania relations\n",
      "Saved article: Tindal Bluff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [00:09<00:07,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Fengxin Road station\n",
      "Saved article: European honey buzzard\n",
      "Saved article: Dorothy Brandon\n",
      "Saved article: 1049 Gotho\n",
      "Saved article: London 1980 International Stamp Exhibition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [00:09<00:06,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Rock Creek Park Golf Course\n",
      "Saved article: Safsaf massacre\n",
      "Saved article: Grotella septempunctata\n",
      "Saved article: Fear of the Digital Remix\n",
      "Saved article: Nothing but Hope and Passion\n",
      "Saved article: Alfred Worden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [00:09<00:01, 13.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Oral pontine reticular nucleus\n",
      "Saved article: Barar Deh, Dodangeh\n",
      "Saved article: Uki waza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [00:10<00:01, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: 2016 KNSB Dutch Single Distance Championships – Women's 3000 m\n",
      "Saved article: 1963 Nova Scotia general election\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [00:11<00:02,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: USS Sagittarius\n",
      "Saved article: Matam Region\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [00:11<00:00, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Motor unit\n",
      "Saved article: Saint Michel d'Aiguilhe\n",
      "Saved article: 1995 CFL season\n",
      "Saved article: Rok Urbanc\n",
      "Saved article: Beach Park Isles\n",
      "Saved article: Mafalda of Castile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [00:11<00:00, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Herbert McCabe\n",
      "Saved article: Ahrue Luster\n",
      "Saved article: Peter Sainthill (died 1571)\n",
      "Skipped disambiguation page: ['David Zilberman (wrestler)', 'David B. Zilberman', 'David Zilberman (economist)']\n",
      "Saved article: Assistant Secretary of Defense for Health Affairs\n",
      "Saved article: William Rant\n",
      "Saved article: Somerset v Stewart\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Joel Hitt\n",
      "Saved article: San Francisco Writers Grotto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import wikipedia\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "# output_wikiディレクトリを作成\n",
    "os.makedirs(\"output_wiki\", exist_ok=True)\n",
    "\n",
    "# 全ての英語Wikipediaページのタイトルを取得する\n",
    "all_titles = list(wikipedia.random(pages=5000))  # 5000ページ分のタイトルを取得\n",
    "\n",
    "# 100個のタイトルをランダムに選択する\n",
    "selected_titles = random.sample(all_titles, 100)\n",
    "\n",
    "def download_page(args):\n",
    "    i, title = args\n",
    "    try:\n",
    "        page = wikipedia.page(title)\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        # 記事が見つからない場合はスキップ\n",
    "        return\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        # 曖昧な記事はスキップする\n",
    "        print(f\"Skipped disambiguation page: {e.options}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    else:\n",
    "        filename = os.path.join(\"output_wiki\", f\"{i:03d}.txt\")\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(page.content)\n",
    "        print(f\"Saved article: {page.title}\")\n",
    "\n",
    "# 選択したタイトルの記事を取得し、保存する\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    list(tqdm(executor.map(download_page, enumerate(selected_titles, start=1)), total=len(selected_titles)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文の分割が完了しました。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kobori/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# NLTKのデータをダウンロード\n",
    "nltk.download('punkt')\n",
    "\n",
    "# output_wikiディレクトリのパス\n",
    "wiki_dir = \"output_wiki\"\n",
    "\n",
    "# output_textディレクトリを作成\n",
    "output_dir = \"output_text\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# output_wikiディレクトリ内のファイルを処理\n",
    "for filename in os.listdir(wiki_dir):\n",
    "    # ファイルパスを構築\n",
    "    file_path = os.path.join(wiki_dir, filename)\n",
    "\n",
    "    # ファイルを読み込む\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # 記事を1文ずつに分割\n",
    "    sentences = sent_tokenize(content)\n",
    "\n",
    "    # output_textディレクトリ内にサブディレクトリを作成\n",
    "    sub_dir_name = os.path.splitext(filename)[0]\n",
    "    sub_dir_path = os.path.join(output_dir, sub_dir_name)\n",
    "    os.makedirs(sub_dir_path, exist_ok=True)\n",
    "\n",
    "    # 分割した文をファイルに保存\n",
    "    for i, sentence in enumerate(sentences, start=1):\n",
    "        sentence_filename = os.path.join(sub_dir_path, f\"{i:03d}.txt\")\n",
    "        with open(sentence_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(sentence)\n",
    "\n",
    "print(\"文の分割が完了しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing subdirectory 1/90: 100%|██████████| 3/3 [00:16<00:00,  5.33s/file]\n",
      "Processing subdirectory 2/90: 100%|██████████| 5/5 [00:17<00:00,  3.48s/file]\n",
      "Processing subdirectory 3/90: 100%|██████████| 51/51 [03:41<00:00,  4.34s/file]\n",
      "Processing subdirectory 4/90: 100%|██████████| 20/20 [01:43<00:00,  5.18s/file]\n",
      "Processing subdirectory 5/90: 100%|██████████| 13/13 [00:56<00:00,  4.35s/file]\n",
      "Processing subdirectory 6/90: 100%|██████████| 37/37 [04:22<00:00,  7.09s/file]\n",
      "Processing subdirectory 7/90: 100%|██████████| 3/3 [00:12<00:00,  4.15s/file]\n",
      "Processing subdirectory 8/90: 100%|██████████| 4/4 [00:16<00:00,  4.12s/file]\n",
      "Processing subdirectory 9/90: 100%|██████████| 7/7 [00:41<00:00,  5.92s/file]\n",
      "Processing subdirectory 10/90: 100%|██████████| 43/43 [04:24<00:00,  6.15s/file]\n",
      "Processing subdirectory 11/90: 100%|██████████| 21/21 [02:01<00:00,  5.77s/file]\n",
      "Processing subdirectory 12/90: 100%|██████████| 42/42 [05:06<00:00,  7.30s/file]\n",
      "Processing subdirectory 13/90: 100%|██████████| 31/31 [03:39<00:00,  7.07s/file]\n",
      "Processing subdirectory 14/90: 100%|██████████| 5/5 [00:28<00:00,  5.61s/file]\n",
      "Processing subdirectory 15/90: 100%|██████████| 3/3 [00:20<00:00,  6.95s/file]\n",
      "Processing subdirectory 16/90: 100%|██████████| 2/2 [00:18<00:00,  9.24s/file]\n",
      "Processing subdirectory 17/90: 100%|██████████| 8/8 [00:48<00:00,  6.02s/file]\n",
      "Processing subdirectory 18/90: 100%|██████████| 3/3 [00:11<00:00,  3.93s/file]\n",
      "Processing subdirectory 19/90: 100%|██████████| 14/14 [01:06<00:00,  4.73s/file]\n",
      "Processing subdirectory 20/90: 100%|██████████| 4/4 [00:12<00:00,  3.09s/file]\n",
      "Processing subdirectory 21/90: 100%|██████████| 10/10 [00:57<00:00,  5.75s/file]\n",
      "Processing subdirectory 22/90: 100%|██████████| 57/57 [04:53<00:00,  5.15s/file]\n",
      "Processing subdirectory 23/90: 100%|██████████| 2/2 [00:08<00:00,  4.03s/file]\n",
      "Processing subdirectory 24/90: 100%|██████████| 4/4 [00:44<00:00, 11.13s/file]\n",
      "Processing subdirectory 25/90: 100%|██████████| 134/134 [06:23<00:00,  2.87s/file]\n",
      "Processing subdirectory 26/90: 100%|██████████| 3/3 [00:17<00:00,  5.94s/file]\n",
      "Processing subdirectory 27/90: 100%|██████████| 20/20 [01:32<00:00,  4.63s/file]\n",
      "Processing subdirectory 28/90: 100%|██████████| 5/5 [00:15<00:00,  3.11s/file]\n",
      "Processing subdirectory 29/90: 100%|██████████| 5/5 [00:14<00:00,  2.86s/file]\n",
      "Processing subdirectory 30/90: 100%|██████████| 13/13 [01:02<00:00,  4.79s/file]\n",
      "Processing subdirectory 31/90: 100%|██████████| 21/21 [01:45<00:00,  5.01s/file]\n",
      "Processing subdirectory 32/90: 100%|██████████| 2/2 [00:07<00:00,  3.91s/file]\n",
      "Processing subdirectory 33/90: 100%|██████████| 6/6 [00:20<00:00,  3.40s/file]\n",
      "Processing subdirectory 34/90: 100%|██████████| 36/36 [04:09<00:00,  6.94s/file]\n",
      "Processing subdirectory 35/90: 100%|██████████| 43/43 [06:24<00:00,  8.94s/file]\n",
      "Processing subdirectory 36/90: 100%|██████████| 9/9 [01:02<00:00,  6.94s/file]\n",
      "Processing subdirectory 37/90: 100%|██████████| 239/239 [22:43<00:00,  5.70s/file]\n",
      "Processing subdirectory 38/90: 100%|██████████| 3/3 [00:21<00:00,  7.18s/file]\n",
      "Processing subdirectory 39/90: 100%|██████████| 29/29 [03:19<00:00,  6.87s/file]\n",
      "Processing subdirectory 40/90: 100%|██████████| 4/4 [00:22<00:00,  5.53s/file]\n",
      "Processing subdirectory 41/90: 100%|██████████| 3/3 [00:13<00:00,  4.36s/file]\n",
      "Processing subdirectory 42/90: 100%|██████████| 8/8 [00:34<00:00,  4.32s/file]\n",
      "Processing subdirectory 43/90: 100%|██████████| 3/3 [00:06<00:00,  2.23s/file]\n",
      "Processing subdirectory 44/90: 100%|██████████| 20/20 [01:59<00:00,  5.97s/file]\n",
      "Processing subdirectory 45/90: 100%|██████████| 40/40 [03:45<00:00,  5.65s/file]\n",
      "Processing subdirectory 46/90: 100%|██████████| 3/3 [00:39<00:00, 13.32s/file]\n",
      "Processing subdirectory 47/90: 100%|██████████| 14/14 [01:17<00:00,  5.52s/file]\n",
      "Processing subdirectory 48/90: 100%|██████████| 83/83 [06:27<00:00,  4.66s/file]\n",
      "Processing subdirectory 49/90: 100%|██████████| 15/15 [01:49<00:00,  7.32s/file]\n",
      "Processing subdirectory 50/90: 100%|██████████| 7/7 [01:10<00:00, 10.01s/file]\n",
      "Processing subdirectory 51/90: 100%|██████████| 10/10 [00:40<00:00,  4.10s/file]\n",
      "Processing subdirectory 52/90: 100%|██████████| 3/3 [00:19<00:00,  6.37s/file]\n",
      "Processing subdirectory 53/90: 100%|██████████| 3/3 [00:11<00:00,  3.79s/file]\n",
      "Processing subdirectory 54/90: 100%|██████████| 17/17 [01:21<00:00,  4.77s/file]\n",
      "Processing subdirectory 55/90: 100%|██████████| 29/29 [04:04<00:00,  8.44s/file]\n",
      "Processing subdirectory 56/90: 100%|██████████| 4/4 [00:13<00:00,  3.29s/file]\n",
      "Processing subdirectory 57/90: 100%|██████████| 14/14 [01:19<00:00,  5.69s/file]\n",
      "Processing subdirectory 58/90: 100%|██████████| 53/53 [02:54<00:00,  3.30s/file]\n",
      "Processing subdirectory 59/90: 100%|██████████| 6/6 [00:34<00:00,  5.69s/file]\n",
      "Processing subdirectory 60/90: 100%|██████████| 18/18 [01:31<00:00,  5.09s/file]\n",
      "Processing subdirectory 61/90: 100%|██████████| 56/56 [05:13<00:00,  5.60s/file]\n",
      "Processing subdirectory 62/90: 100%|██████████| 6/6 [00:28<00:00,  4.71s/file]\n",
      "Processing subdirectory 63/90: 100%|██████████| 59/59 [05:01<00:00,  5.12s/file]\n",
      "Processing subdirectory 64/90: 100%|██████████| 2/2 [00:10<00:00,  5.10s/file]\n",
      "Processing subdirectory 65/90: 100%|██████████| 3/3 [00:33<00:00, 11.12s/file]\n",
      "Processing subdirectory 66/90: 100%|██████████| 4/4 [00:20<00:00,  5.05s/file]\n",
      "Processing subdirectory 67/90: 100%|██████████| 24/24 [01:31<00:00,  3.80s/file]\n",
      "Processing subdirectory 68/90: 100%|██████████| 29/29 [02:05<00:00,  4.31s/file]\n",
      "Processing subdirectory 69/90: 100%|██████████| 7/7 [00:32<00:00,  4.58s/file]\n",
      "Processing subdirectory 70/90: 100%|██████████| 16/16 [01:21<00:00,  5.10s/file]\n",
      "Processing subdirectory 71/90: 100%|██████████| 3/3 [00:18<00:00,  6.14s/file]\n",
      "Processing subdirectory 72/90: 100%|██████████| 12/12 [04:11<00:00, 20.98s/file]\n",
      "Processing subdirectory 73/90: 100%|██████████| 22/22 [02:10<00:00,  5.95s/file]\n",
      "Processing subdirectory 74/90: 100%|██████████| 27/27 [02:25<00:00,  5.40s/file]\n",
      "Processing subdirectory 75/90: 100%|██████████| 13/13 [00:49<00:00,  3.77s/file]\n",
      "Processing subdirectory 76/90: 100%|██████████| 12/12 [00:49<00:00,  4.13s/file]\n",
      "Processing subdirectory 77/90: 100%|██████████| 23/23 [01:26<00:00,  3.78s/file]\n",
      "Processing subdirectory 78/90: 100%|██████████| 6/6 [00:39<00:00,  6.64s/file]\n",
      "Processing subdirectory 79/90: 100%|██████████| 28/28 [02:43<00:00,  5.85s/file]\n",
      "Processing subdirectory 80/90: 100%|██████████| 15/15 [01:38<00:00,  6.58s/file]\n",
      "Processing subdirectory 81/90: 100%|██████████| 2/2 [00:12<00:00,  6.28s/file]\n",
      "Processing subdirectory 82/90: 100%|██████████| 2/2 [00:10<00:00,  5.15s/file]\n",
      "Processing subdirectory 83/90: 100%|██████████| 53/53 [04:25<00:00,  5.02s/file]\n",
      "Processing subdirectory 84/90: 100%|██████████| 5/5 [00:51<00:00, 10.35s/file]\n",
      "Processing subdirectory 85/90: 100%|██████████| 19/19 [02:05<00:00,  6.60s/file]\n",
      "Processing subdirectory 86/90: 100%|██████████| 178/178 [18:54<00:00,  6.37s/file]\n",
      "Processing subdirectory 87/90: 100%|██████████| 24/24 [02:19<00:00,  5.83s/file]\n",
      "Processing subdirectory 88/90: 100%|██████████| 17/17 [01:10<00:00,  4.12s/file]\n",
      "Processing subdirectory 89/90: 100%|██████████| 19/19 [01:26<00:00,  4.54s/file]\n",
      "Processing subdirectory 90/90: 100%|██████████| 40/40 [04:55<00:00,  7.40s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "翻訳が完了しました。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import textwrap\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "from tqdm import tqdm  # プログレスバーを表示するためのライブラリ\n",
    "\n",
    "# 翻訳モデルの設定\n",
    "model_name = 'facebook/mbart-large-50-many-to-many-mmt'\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(model_name)\n",
    "model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# output_textディレクトリのパス\n",
    "input_dir = \"output_text\"\n",
    "\n",
    "# output_japanese_textディレクトリを作成\n",
    "output_dir = \"output_japanese_text\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# サブディレクトリの総数を取得\n",
    "total_subdirs = len(os.listdir(input_dir))\n",
    "\n",
    "# output_textディレクトリ内のサブディレクトリを処理\n",
    "for i, sub_dir_name in enumerate(os.listdir(input_dir), start=1):\n",
    "    sub_dir_path = os.path.join(input_dir, sub_dir_name)\n",
    "\n",
    "    # output_japanese_textディレクトリ内にサブディレクトリを作成\n",
    "    output_sub_dir_path = os.path.join(output_dir, sub_dir_name)\n",
    "    os.makedirs(output_sub_dir_path, exist_ok=True)\n",
    "\n",
    "    # サブディレクトリ内のファイルを処理\n",
    "    files = os.listdir(sub_dir_path)\n",
    "    for filename in tqdm(files, desc=f\"Processing subdirectory {i}/{total_subdirs}\", unit=\"file\"):\n",
    "        file_path = os.path.join(sub_dir_path, filename)\n",
    "\n",
    "        # ファイルを読み込む\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # 文章を小さな部分に分割\n",
    "        sentences = textwrap.wrap(content, width=100)\n",
    "\n",
    "        translated_sentences = []\n",
    "        for sent in sentences:\n",
    "            # 文章をトークナイザーでトークナイズし、モデルが理解できる形式に変換\n",
    "            inputs = tokenizer(sent, return_tensors=\"pt\")\n",
    "\n",
    "            # 翻訳の実行\n",
    "            generated_tokens = model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"ja_XX\"])\n",
    "            translated = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "            translated_sentences.append(translated[0])\n",
    "\n",
    "        # 翻訳された内容をファイルに保存\n",
    "        output_file_path = os.path.join(output_sub_dir_path, filename)\n",
    "        with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for translation in translated_sentences:\n",
    "                f.write(translation + \"\\n\")\n",
    "\n",
    "print(\"翻訳が完了しました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 078: 100%|██████████| 3/3 [00:02<00:00,  1.11file/s]\n",
      "Processing 080: 100%|██████████| 5/5 [00:02<00:00,  2.24file/s]\n",
      "Processing 074: 100%|██████████| 51/51 [00:23<00:00,  2.13file/s]\n",
      "Processing 049: 100%|██████████| 20/20 [00:09<00:00,  2.10file/s]\n",
      "Processing 068: 100%|██████████| 13/13 [00:10<00:00,  1.20file/s]\n",
      "Processing 065: 100%|██████████| 37/37 [00:29<00:00,  1.25file/s]\n",
      "Processing 089: 100%|██████████| 3/3 [00:01<00:00,  2.10file/s]\n",
      "Processing 030: 100%|██████████| 4/4 [00:01<00:00,  2.68file/s]\n",
      "Processing 094: 100%|██████████| 7/7 [00:07<00:00,  1.10s/file]\n",
      "Processing 041: 100%|██████████| 43/43 [00:29<00:00,  1.48file/s]\n",
      "Processing 018: 100%|██████████| 21/21 [00:13<00:00,  1.57file/s]\n",
      "Processing 010: 100%|██████████| 42/42 [00:40<00:00,  1.04file/s]\n",
      "Processing 005: 100%|██████████| 31/31 [00:26<00:00,  1.18file/s]\n",
      "Processing 079: 100%|██████████| 5/5 [00:03<00:00,  1.26file/s]\n",
      "Processing 045: 100%|██████████| 3/3 [00:01<00:00,  2.18file/s]\n",
      "Processing 015: 100%|██████████| 2/2 [00:02<00:00,  1.47s/file]\n",
      "Processing 016: 100%|██████████| 8/8 [00:05<00:00,  1.42file/s]\n",
      "Processing 096: 100%|██████████| 3/3 [00:01<00:00,  2.61file/s]\n",
      "Processing 088: 100%|██████████| 14/14 [00:06<00:00,  2.24file/s]\n",
      "Processing 054: 100%|██████████| 4/4 [00:01<00:00,  3.28file/s]\n",
      "Processing 076: 100%|██████████| 10/10 [00:07<00:00,  1.26file/s]\n",
      "Processing 069: 100%|██████████| 57/57 [00:37<00:00,  1.53file/s]\n",
      "Processing 009: 100%|██████████| 2/2 [00:00<00:00,  2.76file/s]\n",
      "Processing 075: 100%|██████████| 4/4 [00:05<00:00,  1.30s/file]\n",
      "Processing 072: 100%|██████████| 134/134 [00:50<00:00,  2.66file/s]\n",
      "Processing 019: 100%|██████████| 3/3 [00:01<00:00,  2.33file/s]\n",
      "Processing 066: 100%|██████████| 20/20 [00:09<00:00,  2.19file/s]\n",
      "Processing 007: 100%|██████████| 5/5 [00:01<00:00,  2.81file/s]\n",
      "Processing 035: 100%|██████████| 5/5 [00:01<00:00,  2.73file/s]\n",
      "Processing 044: 100%|██████████| 13/13 [00:06<00:00,  1.93file/s]\n",
      "Processing 064: 100%|██████████| 21/21 [00:17<00:00,  1.19file/s]\n",
      "Processing 050: 100%|██████████| 2/2 [00:00<00:00,  2.13file/s]\n",
      "Processing 077: 100%|██████████| 6/6 [00:02<00:00,  2.82file/s]\n",
      "Processing 086: 100%|██████████| 36/36 [00:34<00:00,  1.06file/s]\n",
      "Processing 057: 100%|██████████| 43/43 [01:01<00:00,  1.42s/file]\n",
      "Processing 022: 100%|██████████| 9/9 [00:08<00:00,  1.04file/s]\n",
      "Processing 073:  12%|█▏        | 29/239 [00:18<02:13,  1.57file/s]\n"
     ]
    },
    {
     "ename": "gTTSError",
     "evalue": "429 (Too Many Requests) from TTS API. Probable cause: Unknown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/wiki/lib/python3.10/site-packages/gtts/tts.py:279\u001b[0m, in \u001b[0;36mgTTS.stream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus-\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, idx, r\u001b[38;5;241m.\u001b[39mstatus_code)\n\u001b[0;32m--> 279\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# Request successful, bad response\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://www.google.com/sorry/index?continue=https://translate.google.com/_/TranslateWebserverUi/data/batchexecute&q=EgSFyaIAGMqFhbEGIjDHGmwI1JZCTX8jaBXgXYMctQDvxG6jZ1ljYVcHAZcgYxbJxCeioyTuSKP8EoiBRC0yAXJaAUM",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mgTTSError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;66;03m# 音声ファイルの保存\u001b[39;00m\n\u001b[1;32m     33\u001b[0m         output_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_sub_dir_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m         \u001b[43mtts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m音声ファイルの作成が完了しました。\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/wiki/lib/python3.10/site-packages/gtts/tts.py:335\u001b[0m, in \u001b[0;36mgTTS.save\u001b[0;34m(self, savefile)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Do the TTS API request and write result to file.\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    332\u001b[0m \n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(savefile), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_to_fp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     f\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    337\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, savefile)\n",
      "File \u001b[0;32m~/anaconda3/envs/wiki/lib/python3.10/site-packages/gtts/tts.py:316\u001b[0m, in \u001b[0;36mgTTS.write_to_fp\u001b[0;34m(self, fp)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Do the TTS API request(s) and write bytes to a file-like object.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m \n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, decoded \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream()):\n\u001b[1;32m    317\u001b[0m         fp\u001b[38;5;241m.\u001b[39mwrite(decoded)\n\u001b[1;32m    318\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpart-\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m written to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, idx, fp)\n",
      "File \u001b[0;32m~/anaconda3/envs/wiki/lib/python3.10/site-packages/gtts/tts.py:283\u001b[0m, in \u001b[0;36mgTTS.stream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# Request successful, bad response\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m gTTSError(tts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, response\u001b[38;5;241m=\u001b[39mr)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Request failed\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "\u001b[0;31mgTTSError\u001b[0m: 429 (Too Many Requests) from TTS API. Probable cause: Unknown"
     ]
    }
   ],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# output_japanese_textディレクトリのパス\n",
    "input_dir = \"output_japanese_text\"\n",
    "\n",
    "# output_audioディレクトリを作成\n",
    "output_dir = \"output_audio\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# output_japanese_textディレクトリ内のサブディレクトリを処理\n",
    "for sub_dir_name in os.listdir(input_dir):\n",
    "    sub_dir_path = os.path.join(input_dir, sub_dir_name)\n",
    "\n",
    "    # output_audioディレクトリ内にサブディレクトリを作成\n",
    "    output_sub_dir_path = os.path.join(output_dir, sub_dir_name)\n",
    "    os.makedirs(output_sub_dir_path, exist_ok=True)\n",
    "\n",
    "    # サブディレクトリ内のファイルを処理\n",
    "    files = os.listdir(sub_dir_path)\n",
    "    for i, filename in enumerate(tqdm(sorted(files), desc=f\"Processing {sub_dir_name}\", unit=\"file\"), start=1):\n",
    "        file_path = os.path.join(sub_dir_path, filename)\n",
    "\n",
    "        # ファイルを読み込む\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # gTTS オブジェクトの作成\n",
    "        tts = gTTS(text=content, lang='ja')\n",
    "\n",
    "        # 音声ファイルの保存\n",
    "        output_file_path = os.path.join(output_sub_dir_path, f\"{i:03}.mp3\")\n",
    "        tts.save(output_file_path)\n",
    "\n",
    "        # Googleのサーバーに負荷をかけないように、一定時間待機\n",
    "        time.sleep(1)\n",
    "\n",
    "print(\"音声ファイルの作成が完了しました。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wiki",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
