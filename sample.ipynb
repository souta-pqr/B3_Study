{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Centrolepis aristata\n",
      "Saved article: Rolls-Royce Gnome\n",
      "Saved article: Badah railway station\n",
      "Saved article: Georg von der Marwitz\n",
      "Saved article: Taujėnai Manor\n",
      "Saved article: Mount Cary\n",
      "Saved article: Tasman (National Provincial Championship)\n",
      "Saved article: Deerwood Arboretum and Nature Area\n",
      "Saved article: Return on investment\n",
      "Saved article: Ohtlik lend\n",
      "Saved article: Jason Burnell\n",
      "Saved article: Games People Play (book)\n",
      "Saved article: Spain at the 1952 Winter Olympics\n",
      "Saved article: 2011 Lexus of Las Vegas Open\n",
      "Saved article: Jack Wild\n",
      "Saved article: Allan Luke\n",
      "Saved article: Reseda Beach\n",
      "Saved article: Vilela people\n",
      "Saved article: List of newspapers in Bahrain\n",
      "Saved article: Squatting in Fiji\n",
      "Saved article: Ph.D. (Art Farmer album)\n",
      "Saved article: Euphemia Mondich\n",
      "Saved article: Isoetes riparia\n",
      "Saved article: Australian Salaried Medical Officers' Federation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/souta-pqr/anaconda3/envs/wiki/lib/python3.10/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /home/souta-pqr/anaconda3/envs/wiki/lib/python3.10/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped disambiguation page: ['Bill Hume (footballer)', 'Bill Hume (cartoonist)', 'Billy Hume', 'Willie Hume', 'William Hume (Cape politician)', 'William Errington Hume', 'William H. Hume', 'William J. Hume', 'William Fraser Hume', 'William Hume-Williams', 'William Hume Blake', 'William Hume-Rothery', 'William Hulme (disambiguation)']\n",
      "Saved article: Duplicate poker\n",
      "Saved article: Arthur Sorin\n",
      "Saved article: Sartor (surname)\n",
      "Saved article: 1956 Ball State Cardinals football team\n",
      "Saved article: Neil Lewis (journalist)\n",
      "Saved article: Pemagatsel\n",
      "Saved article: Feneley\n",
      "Saved article: 2007–08 Euroleague\n",
      "Saved article: René Olivares\n",
      "Saved article: Lancaster, Newfoundland and Labrador\n",
      "Saved article: Chicago P.D. season 8\n",
      "Saved article: Bengt Bengtsson Oxenstierna\n",
      "Saved article: Ženje\n",
      "Saved article: Mshindo Msolla\n",
      "Saved article: The Adventures of Milo and Otis\n",
      "Saved article: Monmouth Oaks\n",
      "Saved article: Harold Rosenwald\n",
      "Saved article: South Carolina Highway 248\n",
      "Saved article: Moallem Kalayeh Rural District\n",
      "Saved article: Tayeb Salih\n",
      "Saved article: Journal of Community and Applied Social Psychology\n",
      "Saved article: Essex Thameside\n",
      "Saved article: Oborín\n",
      "Saved article: John Gerard (Royalist)\n",
      "Saved article: Greek ship Ierax\n",
      "Saved article: Theater auf der Wieden\n",
      "Saved article: Steve Kazee\n",
      "Saved article: Legarda, Navarre\n",
      "Saved article: Chumy Chúmez\n",
      "Saved article: The Penrose Annual\n",
      "Saved article: Gösta Ekspong\n",
      "Saved article: Lancair\n",
      "Saved article: Globus (weekly)\n",
      "Saved article: Asha Bowen\n",
      "Saved article: Deadboy & the Elephantmen\n",
      "Saved article: George Mouzalon\n",
      "Saved article: Amrita Shinde\n",
      "Saved article: 2015–16 England Korfball League\n",
      "Saved article: Middle Yanggao Road station\n",
      "Saved article: Douglas Jackson (author)\n",
      "Saved article: Andrew Thomson (Scottish footballer)\n",
      "Saved article: Spring on the Oder\n",
      "Saved article: L'Herne\n",
      "Saved article: Mohammed ben Hadou\n",
      "Saved article: Pape Ciré Dia\n",
      "Saved article: Harland Bowden\n",
      "Saved article: Ayuntamiento de Manila\n",
      "Skipped disambiguation page: ['George Jarvis (cricketer)', 'George Jarvis (footballer)', 'George Jarvis (Philhellene)', 'George A. Jarvis', 'George Stephen Benjamin Jarvis']\n",
      "Saved article: Riyadh Al-Arini\n",
      "Skipped disambiguation page: ['Gornja Bukovica (Maglaj)', 'Bukovica Gornja', 'Gornja Bukovica, Valjevo', 'Gornja Bukovica, Montenegro', 'Donja Bukovica (disambiguation)']\n",
      "Saved article: Irgun bombing of police headquarters in Haifa\n",
      "Saved article: Sakutō, Okayama\n",
      "Saved article: Jack Evans (footballer, born 1908)\n",
      "Saved article: Hired armed cutter Hero\n",
      "Saved article: Alabama Airborne\n",
      "Saved article: Vivian Metcalfe\n",
      "Saved article: 1946–47 SK Rapid Wien season\n",
      "Saved article: 2010–11 Bolton Wanderers F.C. season\n",
      "Saved article: The Evian Championship\n",
      "Saved article: Lowell City Airport\n",
      "Saved article: Data Carrier Detect\n",
      "Saved article: William Everingham\n",
      "Saved article: 2023 Kilkenny Intermediate Hurling Championship\n",
      "Saved article: Iron germanide\n",
      "Saved article: Neserkauhor\n",
      "Skipped disambiguation page: ['Kangyi, Banmauk', 'Kangyi, Bhamo', 'Kangyi, Kale', 'Kangyi, Mudon', 'Kangyi, Wenshang County']\n",
      "Saved article: Anton Skulberg\n",
      "Saved article: Yegor Proshkin\n",
      "Saved article: Comparison of the Community of Christ and the Church of Jesus Christ of Latter-day Saints\n",
      "Saved article: Wiszniów\n",
      "Skipped disambiguation page: ['August Storck', 'Storck Barracks', 'Storck, Virginia', 'Abraham Storck', 'Anton von Störck', 'Bernd Storck', 'Carl Storck', 'Carol Storck', 'Cecilia Cuțescu-Storck', 'Erik Storck', 'Frederic Storck', 'Georg Störck', 'George H. Storck', 'Gunther Storck', 'Henri Storck', 'Hermann Baagøe Storck', 'Jacobus Storck', 'Karl Storck', 'Klaus Storck', 'Shelby Storck', 'Storch (disambiguation)', 'Stork (disambiguation)']\n",
      "Saved article: Académie Internationale de Droit Constitutionnel\n",
      "Saved article: Helga Rullestad\n",
      "Saved article: Terminalia rerei\n",
      "Saved article: 2007–08 Premier Academy League\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import wikipedia\n",
    "\n",
    "# output_wikiディレクトリを作成\n",
    "os.makedirs(\"output_wiki\", exist_ok=True)\n",
    "\n",
    "# 全ての英語Wikipediaページのタイトルを取得する\n",
    "all_titles = list(wikipedia.random(pages=5000))  # 5000ページ分のタイトルを取得\n",
    "\n",
    "# 100個のタイトルをランダムに選択する\n",
    "selected_titles = random.sample(all_titles, 100)\n",
    "\n",
    "# 選択したタイトルの記事を取得し、保存する\n",
    "for i, title in enumerate(selected_titles, start=1):\n",
    "    try:\n",
    "        page = wikipedia.page(title)\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        # 記事が見つからない場合はスキップ\n",
    "        continue\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        # 曖昧な記事はスキップする\n",
    "        print(f\"Skipped disambiguation page: {e.options}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    else:\n",
    "        filename = os.path.join(\"output_wiki\", f\"{i:03d}.txt\")\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(page.content)\n",
    "        print(f\"Saved article: {page.title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/souta-pqr/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文の分割が完了しました。\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# NLTKのデータをダウンロード\n",
    "nltk.download('punkt')\n",
    "\n",
    "# output_wikiディレクトリのパス\n",
    "wiki_dir = \"output_wiki\"\n",
    "\n",
    "# output_textディレクトリを作成\n",
    "output_dir = \"output_text\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# output_wikiディレクトリ内のファイルを処理\n",
    "for filename in os.listdir(wiki_dir):\n",
    "    # ファイルパスを構築\n",
    "    file_path = os.path.join(wiki_dir, filename)\n",
    "\n",
    "    # ファイルを読み込む\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # 記事を1文ずつに分割\n",
    "    sentences = sent_tokenize(content)\n",
    "\n",
    "    # output_textディレクトリ内にサブディレクトリを作成\n",
    "    sub_dir_name = os.path.splitext(filename)[0]\n",
    "    sub_dir_path = os.path.join(output_dir, sub_dir_name)\n",
    "    os.makedirs(sub_dir_path, exist_ok=True)\n",
    "\n",
    "    # 分割した文をファイルに保存\n",
    "    for i, sentence in enumerate(sentences, start=1):\n",
    "        sentence_filename = os.path.join(sub_dir_path, f\"{i:03d}.txt\")\n",
    "        with open(sentence_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(sentence)\n",
    "\n",
    "print(\"文の分割が完了しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/souta-pqr/anaconda3/envs/wiki/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/souta-pqr/anaconda3/envs/wiki/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pysbd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm  # プログレスバーを表示するためのライブラリ\n",
    "\n",
    "# 翻訳モデルの設定\n",
    "fugu_translator = pipeline('translation', model='staka/fugumt-en-ja')\n",
    "\n",
    "# output_textディレクトリのパス\n",
    "input_dir = \"output_text\"\n",
    "\n",
    "# output_japanese_textディレクトリを作成\n",
    "output_dir = \"output_japanese_text\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# サブディレクトリの総数を取得\n",
    "total_subdirs = len(os.listdir(input_dir))\n",
    "\n",
    "# output_textディレクトリ内のサブディレクトリを処理\n",
    "for i, sub_dir_name in enumerate(os.listdir(input_dir), start=1):\n",
    "    sub_dir_path = os.path.join(input_dir, sub_dir_name)\n",
    "\n",
    "    # output_japanese_textディレクトリ内にサブディレクトリを作成\n",
    "    output_sub_dir_path = os.path.join(output_dir, sub_dir_name)\n",
    "    os.makedirs(output_sub_dir_path, exist_ok=True)\n",
    "\n",
    "    # サブディレクトリ内のファイルを処理\n",
    "    files = os.listdir(sub_dir_path)\n",
    "    for filename in tqdm(files, desc=f\"Processing subdirectory {i}/{total_subdirs}\", unit=\"file\"):\n",
    "        file_path = os.path.join(sub_dir_path, filename)\n",
    "\n",
    "        # ファイルを読み込む\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # 英語の文章を1文ずつに分割\n",
    "        seg_en = pysbd.Segmenter(language=\"en\", clean=False)\n",
    "        sentences_en = seg_en.segment(content)\n",
    "\n",
    "        # 英語から日本語に翻訳\n",
    "        translations = fugu_translator(sentences_en)\n",
    "\n",
    "        # 翻訳された内容をファイルに保存\n",
    "        output_file_path = os.path.join(output_sub_dir_path, filename)\n",
    "        with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for translation in translations:\n",
    "                f.write(translation['translation_text'] + \"\\n\")\n",
    "\n",
    "print(\"翻訳が完了しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 音声ファイルに変換する\n",
    "import os\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
    "\n",
    "os.makedirs(\"audio_files\", exist_ok=True)\n",
    "\n",
    "model_name = \"facebook/wav2vec2-large-xlsr-japanese\"\n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(model_name)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name)\n",
    "\n",
    "for i, ja_sentence in enumerate(ja_sentences):\n",
    "    speech = model.generate(tokenizer(ja_sentence, return_tensors=\"pt\").input_ids)\n",
    "    filename = f\"audio_files/sentence_{i}.wav\"\n",
    "    tokenizer.save_audio(speech, filename)\n",
    "    print(f\"Saved audio file: {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wiki",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
